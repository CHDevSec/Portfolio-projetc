# Vulnerability Management — Technical Documentation

## 1. Executive Summary
A central Vulnerability Management Program (VMP) was developed to automate discovery, prioritize risk, enforce remediation SLAs, and maintain an auditable remediation trail. Core scanning technologies are **Nessus** (network & host), **Snyk** (developer dependency / IaC scanning), and **AWS Inspector** (cloud workload scanning). Findings are normalized and pushed to a centralized tracking board in Jira and visualized in ELK for organization-wide visibility.

## 2. Goals, Scope & Non-Goals

### Goals
- Detect and classify vulnerabilities across on-prem, cloud, and application code
- Prioritize remediation using risk-based scoring (CVSS + business context + exploitability)
- Automate ticket creation and SLA enforcement in Jira
- Provide dashboards and KPIs for leadership and engineering
- Validate fixes via retests and penetration testing on critical assets

### In Scope
- Hosts, network devices, containers, serverless functions, application dependencies, and IaC templates
- Tools: **Nessus**, **Snyk**, **AWS Inspector**, **Jira**, **ELK Stack**, **Python automation**

### Out of Scope
- Offensive exploitation guidance or weaponized PoC publication
- Focus on detection, prioritization, remediation, and verification

## 3. System Architecture & Data Flows

### High-Level Architecture
```
[ Nessus / Snyk / AWS Inspector ] 
    ↓
[ Ingestion / Normalizer ] 
    ↓
[ ELK (indices) ] 
    ↓
[ Scoring Engine ] 
    ↓
[ Jira (tickets) ]
    ↓
[ Grafana / Kibana dashboards ]
```

### Core Components
- **Scanners**: Nessus, Snyk, AWS Inspector
- **Aggregation**: Filebeat/Logstash → ELK (Elasticsearch indices)
- **Ticketing**: Normalized findings → Jira REST API
- **Dashboards**: Kibana for visualization and reporting
- **Remediation**: Engineering fixes → verification → closure

## 4. Canonical Vulnerability Data Model

### Required Fields
```json
{
  "finding_id": "string",
  "scanner": "nessus|snyk|aws_inspector",
  "title": "string",
  "description": "string",
  "cvss_base": "float (0.0-10.0)",
  "cvss_vector": "string",
  "exploit_available": "boolean",
  "published_date": "datetime",
  "first_seen": "datetime",
  "last_seen": "datetime",
  "severity": "scanner_label",
  "normalized_severity": "Critical|High|Medium|Low",
  "resource_type": "host|container|repo|image|iam",
  "resource_id": "string",
  "ip": "string",
  "hostname": "string",
  "region": "string",
  "account_id": "string",
  "port": "string",
  "protocol": "string",
  "remediation": "text",
  "business_owner": "string",
  "exposure": "publicly_reachable|internal|behind_waf",
  "ticket_id": "string",
  "status": "open|in-progress|mitigated|closed",
  "evidence": "string"
}
```

## 5. Ingestion & Normalization

### Approach
- **Filebeat/Logstash** or lightweight Python ETL service
- Fetches scan results via APIs (Nessus, Snyk, AWS Inspector)
- Normalizes to canonical model
- Indexes into Elasticsearch with optional queue messaging

### Indexing Strategy
- Indices per scanner: `vuln-nessus-2025.10`, `vuln-snyk-2025.10`
- Unified index: `vuln-YYYY.MM` with searchable scanner field
- Use index templates & ILM for retention

### Normalization Examples
- **Nessus JSON** → map `plugin_id + plugin_name` → `finding_id`
- **Snyk JSON** → `package/version/path` → `resource_type = repo/dependency`
- **AWS Inspector** → convert `findingArn` and severity into normalized fields

## 6. Scoring & Prioritization

### Risk-Based Scoring Formula
```
priority_score = 0.50 * (cvss_base / 10.0) 
               + 0.30 * (asset_criticality / 10.0) 
               + 0.15 * exploitability_score 
               + 0.05 * exposure_score
```

### Priority Mapping
- `priority_score >= 0.80` → **Critical**
- `0.60 <= score < 0.80` → **High**
- `0.40 <= score < 0.60` → **Medium**
- `< 0.40` → **Low**

### Scoring Factors
- **Asset Criticality**: 0-10 (10 = crown jewel infrastructure)
- **Exploitability Score**: 0-1 (1 if verified PoC, 0.5 if proof-of-concept, 0 if none)
- **Exposure Score**: 0-1 (1 = internet-exposed, 0.5 = behind WAF, 0 = internal only)

## 7. Ticketing & Jira Integration

### Jira Project Model
- **Project**: `VULN`
- **Issue Types**: `VULNERABILITY`, `PEN_TEST`, `EXCEPTION`

### Essential Fields
- **Summary**: `[Critical] CVE-YYYY-NNNN - <short summary> - <hostname>`
- **Description**: Full normalized description + remediation steps + evidence links
- **Priority**: Critical/High/Medium/Low (mapped from priority_score)
- **Labels**: `nessus|snyk|aws-inspector`, environment tag, `iot|prod`
- **Custom Fields**: CVSS, Exploit Available, Asset Criticality, Business Owner, SLA date

### Automated Creation Policy
- Create ticket if `priority_score >= 0.60`
- Lower scores → Slack/Email digest for triage
- Update existing tickets instead of creating duplicates

### Python Example: Create Jira Issue
```python
import requests

JIRA_BASE = "https://your-jira.example.com"
API_TOKEN = "{{JIRA_API_TOKEN}}"
PROJECT_KEY = "VULN"

headers = {
    "Authorization": f"Bearer {API_TOKEN}",
    "Content-Type": "application/json"
}

payload = {
    "fields": {
        "project": {"key": PROJECT_KEY},
        "summary": "[High] CVE-2024-XXXX - Example vulnerability - host-01",
        "issuetype": {"name": "VULNERABILITY"},
        "description": "Full vulnerability description + remediation steps.\n\nEvidence: https://s3.example.com/reports/nessus/123.json",
        "priority": {"name": "High"},
        "labels": ["nessus", "prod"],
        "customfield_12345": 8.7  # CVSS custom field
    }
}

r = requests.post(f"{JIRA_BASE}/rest/api/2/issue", json=payload, headers=headers)
r.raise_for_status()
print(r.json())
```

## 8. CI/CD Integration & Developer Workflows

### Snyk Integration
- **On PR**: Run `snyk test` for dependencies & `snyk iac test` for IaC
- **Policies**:
  - Block PR if Critical vulnerability in direct dependency
  - For transitive High vulnerabilities, post PR comment + auto-create Jira ticket

### GitLab CI Example
```yaml
stages:
  - test

snyk_scan:
  image: node:18
  stage: test
  script:
    - npm ci
    - npm install -g snyk
    - snyk auth $SNYK_TOKEN
    - snyk test --json > snyk-result.json || true
    - python scripts/ingest_snyk_to_vmp.py snyk-result.json
  artifacts:
    paths:
      - snyk-result.json
```

## 9. Penetration Testing Program

### Scope & Cadence
- **Quarterly**: High-impact systems
- **Annual**: Broader coverage
- **Immediate**: After major public release or architecture change

### Process
1. **Scoping & ROE**: Define targets, testing windows, emergency contacts
2. **Recon & Enumeration**: Passive discovery → active scanning
3. **Exploitation**: Focused, limited testing on pre-approved targets
4. **Post-Exploit**: Evidence capture, risk classification, mitigations
5. **Reporting & Retest**: Detailed guidance + verification checklist

## 10. Dashboards & ELK Design

### Indices & Templates
- **Index**: `vuln-findings-YYYY.MM`
- **Mappings**: `resource_id.keyword`, `cvss_base`, `priority_score`, `ticket_id.keyword`, `status.keyword`, `business_owner.keyword`, `first_seen`, `last_seen`

### Kibana Dashboards
- **Overview**: Active vulnerabilities by severity, weekly trends, new vs. closed
- **SLA Dashboard**: Issues by days open, SLA breaches
- **Asset Risk Heatmap**: `asset_criticality` vs. `count(vulns)`
- **Scanner Coverage**: Last scan time per asset, coverage gaps

### Sample KQL Queries
```kql
# Critical external vulnerabilities
normalized_severity: "Critical" and exposure: "public"

# SLA breaches
status: "open" and sla_due_date < now

# Recent findings by scanner
first_seen > now-7d and scanner: "nessus"
```

## 11. Remediation Verification & Retesting

### Verification Steps
- **Host & Network**: Targeted Nessus re-scan of specific host/port
- **Code Dependencies**: Verify Snyk test in new build
- **Cloud Issues**: Re-run AWS Inspector on resource

### Automation
When Jira status moves to "Mitigated" with evidence URL:
1. Trigger re-scan of relevant resource(s)
2. If finding removed or CVSS reduced → mark "Verified" and close
3. If still present → move back to "Open" and set new deadline

## 12. SLAs, Metrics & KPIs

### SLA Examples
- **Critical**: 72 hours (3 days)
- **High**: 14 days
- **Medium**: 30 days
- **Low**: 90 days

### Core KPIs
- **Mean Time To Remediate (MTTR)** per severity
- **Percentage of critical vulnerabilities** remediated within SLA
- **Time-to-detect** (scanner cadence vs. first_seen)
- **Open vulnerabilities by age** (0-7, 8-30, 31-90, >90 days)
- **Scanner coverage** (assets scanned in last 30 days)
- **False positive rate** (manually marked)

### Measurement
Use Kibana to compute MTTR: `avg(resolution_date - created_date)` grouped by `normalized_severity`

## 13. Governance: Meetings & Workflows

### Weekly Security Review (Triage)
**Attendees**: Security lead, Vulnerability owner, DevOps, Product/Service owner

**Agenda**:
- Review new Critical/High findings
- Validate asset criticality and business context
- Assign remediation tasks & update Jira
- Identify blockers and request exceptions

**Output**: Updated Jira statuses, owners, action items

### Monthly Vulnerability Forum
**Attendees**: Security leadership, Engineering managers, DevOps, SRE, Product leads

**Agenda**:
- Trend analysis, SLA performance, pen-test results
- Prioritization of cross-team remediation projects
- Policy adjustments

**Output**: Roadmap items, architectural changes

## 14. Automation Examples & Playbooks

### A. Auto-create Jira Ticket
```python
# Pseudocode
if priority_score >= 0.60 and existing_ticket == None:
    create_jira_issue()
    set_sla_due_date(created + SLA_days(priority))
elif existing_ticket:
    append_evidence()
    update_status()
```

### B. Update Ticket with Evidence
```python
import requests

JIRA_BASE = "https://jira.example.com"
API_TOKEN = "{{JIRA_API_TOKEN}}"
ISSUE_KEY = "VULN-1234"
attachment_path = "/tmp/nessus_report_1234.json"

headers = {"Authorization": f"Bearer {API_TOKEN}"}
files = {"file": open(attachment_path, "rb")}

r = requests.post(
    f"{JIRA_BASE}/rest/api/2/issue/{ISSUE_KEY}/attachments",
    headers={**headers, "X-Atlassian-Token": "no-check"},
    files=files
)
r.raise_for_status()
print("Attachment uploaded")
```

### C. GitLab CI: Block Merge on Critical Snyk Vuln
```yaml
name: Snyk Scan
on: [pull_request]
jobs:
  snyk:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Snyk test
        uses: snyk/actions/node@master
        with:
          args: test --json > snyk-result.json
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      - name: Upload
        uses: actions/upload-artifact@v3
        with:
          name: snyk-report
          path: snyk-result.json
```

## 15. Data Retention, Backups & Compliance

### Retention
- **Scanner raw output**: 1 year (cold storage after 90 days)
- **Normalized vuln indices**: 2 years hot/warm, older to cold S3
- **Jira issues**: Per company policy (often indefinite)

### Backups
- Daily snapshots of Elasticsearch indices to object storage
- Wazuh index backups per schedule

### Compliance
- Map against frameworks (NIST CSF, PCI DSS, ISO27001)
- Attach evidence for auditors (scan artifacts, tickets, verification)

## 16. False Positive Handling & Exception Process

### Triage
If finding is suspected FP:
1. Record why this is FP and validation steps
2. Close with resolution = "False Positive" OR move to "Exception"
3. Keep FP rate metric to tune scanner rules

### Exception Approval
- Document compensating controls
- Approval chain (security manager + asset owner)
- Set expiration (30-90 days) and auto re-evaluation

## 17. Implementation Roadmap

### Phase 0 — Foundations
- [ ] Create Jira project + custom fields + templates
- [ ] Provision ELK stack and index templates
- [ ] Set up secure credentials and vault integration

### Phase 1 — Onboarding Scanners
- [ ] Integrate Nessus & schedule scan policies
- [ ] Integrate Snyk into CI pipelines for top 10 repos
- [ ] Enable AWS Inspector for critical AWS accounts

### Phase 2 — Normalization & Automation
- [ ] Build ETL for finding normalization
- [ ] Implement scoring engine and ticket creation
- [ ] Implement initial dashboards

### Phase 3 — Governance
- [ ] Start weekly triage meetings
- [ ] Run first pen test and remediate critical findings
- [ ] Publish monthly Vulnerability Forum report

### Phase 4 — Scale & Optimization
- [ ] Expand Snyk to all repositories
- [ ] Tune Nessus scan policies
- [ ] Add asset discovery automation
- [ ] Implement ILM and index optimization

## 18. Security Considerations

### Safe Scanning Practices
- Maintain scanning calendar and whitelist testing windows
- Use credentials/agent-based scans for deep scanning
- Secure scanner consoles behind internal network & MFA
- Limit ETL/ticketing automation access and log all actions

## 19. Appendix — Configuration Examples

### A. Elasticsearch Mapping
```json
{
  "mappings": {
    "properties": {
      "finding_id": { "type": "keyword" },
      "scanner": { "type": "keyword" },
      "cvss_base": { "type": "float" },
      "priority_score": { "type": "float" },
      "resource_id": { "type": "keyword" },
      "first_seen": { "type": "date" },
      "status": { "type": "keyword" }
    }
  }
}
```

### B. Nessus Scheduling Policy
- **Internal full scan**: Weekly Sunday 02:00, credentials discovery enabled
- **External perimeter**: Daily 03:00, limited plugin set, no intrusive exploits

## 20. Final Recommendations

### Next Steps
1. **Start small**: Onboard 1-2 critical services to validate automation
2. **Tune scoring**: Use real data for 2-4 weeks with stakeholders
3. **Automate retest**: Reduce manual verification overhead
4. **Document playbooks**: Include RBAC and processes in Vulnerability Forum
5. **Measure & iterate**: Refine after first 90 days

### Success Metrics
- 60% reduction in manual intervention
- Faster anomaly detection through automated workflows
- Improved uptime visibility across distributed environments
- Complete audit trail for compliance requirements